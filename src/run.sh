#!/bin/bash

# æ¿€æ´»condaç¯å¢ƒ
source /volume/pt-train/users/wzhang/ghchen/zh/miniconda3/bin/activate llf

# é»˜è®¤å‚æ•°
DATASETS="${1:-alpaca_10k}"
PROBE_TYPES="${2:- mean}" #hs_last_mlp mean max
MAX_SAMPLES="${3:-4000}"

echo "========================================="
echo "CoBench å®Œæ•´ Pipeline"
echo "========================================="
echo "æ•°æ®é›†: $DATASETS"
echo "Probe ç±»å‹: $PROBE_TYPES"
echo "æœ€å¤§æ ·æœ¬æ•°: $MAX_SAMPLES"

# ========================================
# æµ‹è¯•æ•°æ®çš„æ­¥éª¤
# ========================================
# å¯åŠ¨æ¨¡å‹æœåŠ¡
# cd inference
# python start.py \
#   --model_path "/volume/pt-train/models/Llama-3.1-8B-Instruct" \
#   --base_port 8001 \
#   --gpu_list "0,1,2,3"


# å¦‚æœæµ‹è¯•égeneralæ•°æ® éœ€è¦å¯åŠ¨xVerify
# CUDA_VISIBLE_DEVICES=4 \
# vllm serve /volume/pt-train/users/wzhang/ghchen/zh/models/xVerify-9B-C \
#   --host 0.0.0.0 \
#   --port 8000 \
#   --tensor-parallel-size 1 \
#   --served-model-name xVerify \
#   --trust-remote-code

# ç­‰å¾…æ¨¡å‹æœåŠ¡å¯åŠ¨å®Œæˆåï¼Œè¿è¡Œ scores
# scores
# python run_new.py --mode get_scores --datasets $DATASETS
# # # logits
# python run_new.py --mode get_logits --datasets $DATASETS
# # training probe
python run_new.py --mode train --datasets $DATASETS --probe_types $PROBE_TYPES --max_samples $MAX_SAMPLES --save_loss_history


# # è¯„ä¼°
# python run.py --mode eval_probe --datasets $DATASETS --probe_types $PROBE_TYPES

echo ""
echo "========================================="
echo "ğŸ‰ å®Œæ•´ Pipeline æ‰§è¡ŒæˆåŠŸï¼"
echo "========================================="
echo "ç»“æœä¿å­˜ä½ç½®:"
echo "  - Scores:    results/"
echo "  - Logits:    ../hs/"
echo "  - æ¨¡å‹:      probe_save/test/"
echo "  - è®­ç»ƒå†å²:   probe_save/loss/"
echo "  - è¯„ä¼°ç»“æœ:   metric_results/eval/"
