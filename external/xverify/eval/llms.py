import os
import configparser

from openai._exceptions import APITimeoutError

from loguru import logger
from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_random_exponential


# Define default configuration path for models
MODELS_CONFIG = "models.ini"

# Define retry strategy parameters
RETRY_TIMES = 30
WAIT_TIME_UPPER = 30
WAIT_TIME_LOWER = 10

TIMEOUT = 60


class LLMs:
    """
    A class to manage and interact with Language Learning Models (LLMs).

    Attributes:
        model_name (str): The name of the model to be used.
        config_path (str): The path to the configuration file containing model settings.
        llms_config (ConfigParser): Configuration parser object for reading model configurations.
        common_params (dict): Common parameters for all models.
        key_dict (dict): Dictionary containing API keys for different models.
        model_info (dict): Information about the selected model.
        url (str): Base URL for the API endpoint.
        key (str): API key for authentication.
        _model_name (str): Model name used for API requests.
    """

    def __init__(
        self,
        model_name: str = None,
        config_path: str = MODELS_CONFIG
    ):
        """
        Initializes an instance of the LLMs class.

        Args:
            model_name (str, optional): Name of the model to be used. Defaults to None.
            config_path (str, optional): Path to the configuration file. Defaults to MODELS_CONFIG.
        """
        self.model_name = model_name
        self.config_path = config_path
        self.load_llms_config(self.config_path)

    def load_llms_config(self, config_file: str):
        """
        Loads the configuration for the specified model from a given configuration file.

        Args:
            config_file (str): Path to the configuration file.

        Raises:
            FileNotFoundError: If the configuration file does not exist.
            KeyError: If the specified model is not found in the configuration file.
        """
        if not os.path.exists(config_file):
            logger.error(f"Configuration file '{config_file}' not found.")
            raise FileNotFoundError(
                f"Configuration file '{config_file}' not found.")
        
        self.llms_config = configparser.ConfigParser()
        self.llms_config.read(config_file)

        # Load common parameters for all models
        self.common_params = {
            'max_tokens': self.llms_config.getint('common_params', 'max_tokens'),
            'temperature': self.llms_config.getfloat('common_params', 'temperature'),
            'top_p': self.llms_config.getfloat('common_params', 'top_p')
            # Other common parameters can be added here
        }

        try:
            # Load specific information for the requested model
            self.model_info = self.llms_config[self.model_name]
        except Exception as e:
            logger.error(f"'{self.model_name}' model does not exist in '{self.config_path}'")
            raise 
        
        # Extract base URL and API key for the model
        self.url = self.model_info['base_url']
        self.key = self.model_info['api_key']
        # Model name used for making API requests
        self._model_name = self.model_info['model']

    @retry(wait=wait_random_exponential(min=WAIT_TIME_LOWER, max=WAIT_TIME_UPPER), stop=stop_after_attempt(RETRY_TIMES), reraise=True)
    def request(self, prompt):
        """
        Sends a request to the specified language model with a given prompt.

        Args:
            prompt (str): The input text or message to send to the model.

        Returns:
            str: The response generated by the model.

        Warnings:
            Logs any exceptions that occur during the request process.
        """
        try:
            model = OpenAI(
                base_url=self.url,
                api_key=self.key
            )

            response_obj = model.chat.completions.create(
                model=self._model_name,
                messages=[
                    {
                        'role': 'user', 
                        'content': prompt
                    }
                ],
                timeout=TIMEOUT,
                **self.common_params
            )

            return response_obj.choices[0].message.content
        except APITimeoutError as e:
            logger.warning(f"Request timed out: {repr(e)}")
            return ''
        except Exception as e:
            logger.warning(repr(e))
            raise

    @retry(wait=wait_random_exponential(min=WAIT_TIME_LOWER, max=WAIT_TIME_UPPER), stop=stop_after_attempt(RETRY_TIMES), reraise=True)
    def request_message(self, messages):
        """
        Sends a request to the specified language model with a given prompt.

        Args:
            messages (list): A list of messages to send to the model.

        Returns:
            str: The response generated by the model.

        Warnings:
            Logs any exceptions that occur during the request process.
        """
        try:
            model = OpenAI(
                base_url=self.url,
                api_key=self.key
            )

            response_obj = model.chat.completions.create(
                model=self._model_name,
                messages=messages,
                timeout=TIMEOUT,
                **self.common_params
            )

            return response_obj.choices[0].message.content
        except APITimeoutError as e:
            logger.warning(f"Request timed out: {repr(e)}")
            return ''
        except Exception as e:
            logger.warning(repr(e))
            raise


if __name__ == '__main__':
    llm = LLMs(model_name='GPT-4o')
    response = llm.request('who are you?')
    print(response)