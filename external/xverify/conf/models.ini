[common_params]
max_tokens = 2048
temperature = 0.1
top_p = 0.7

[api_key]
gpt_key = sk-xxx
inference_key = sk-xxx

[GPT_4o]
model = gpt-4o
base_url = http://xxx.xxx.xxx/v1
api_key = sk-xxx

[LLaMA3.1-8B]
model = Meta-Llama-3.1-8B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[DeepSeek-R1-Distill-Llama-8B]
model = DeepSeek-R1-Distill-Llama-8B
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[DeepSeek-R1-Distill-Qwen-1.5B]
model = DeepSeek-R1-Distill-Qwen-1.5B
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[DeepSeek-R1-Distill-Qwen-7B]
model = DeepSeek-R1-Distill-Qwen-7B
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[DeepSeek-R1-Distill-Qwen-14B]
model = DeepSeek-R1-Distill-Qwen-14B
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Qwen2-7B-Instruct]
model = Qwen2-7B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Qwen2-1.5B-Instruct]
model = Qwen2-1.5B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Qwen2.5-7B-Instruct]
model = Qwen2.5-7B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Qwen2.5-14B-Instruct]
model = Qwen2.5-14B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[InternLM2.5-7B-Chat]
model = internlm2_5-7b-chat
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[ChatGLM3-6B]
model = chatglm3-6b
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[GLM-4-9B-Chat]
model = glm-4-9b-chat
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Gemma-2-9B-it]
model = Gemma-2-9B-it
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Gemma-2-2B-it]
model = Gemma-2-2B-it
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Llama-3.2-1B-Instruct]
model = Llama-3.2-1B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Llama-3.2-3B-Instruct]
model = Llama-3.2-3B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Llama-3.2-1B-Instruct]
model = Llama-3.2-1B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Llama-3.2-3B-Instruct]
model = Llama-3.2-3B-Instruct
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[QwQ-32B]
model = QwQ-32B
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[Phi-4]
model = Phi-4
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key


[xVerify-Llama-3.1-8B-QLoRA]
model = xVerify-Llama-3.1-8B-QLoRA
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[xVerify-Gemma-2-2B-QLoRA]
model = xVerify-Gemma-2-2B-QLoRA
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[xVerify-Qwen2.5-14B-QLoRA]
model = xVerify-Qwen2.5-14B-QLoRA
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key

[xVerify-Qwen2.5-7B-QLoRA]
model = xVerify-Qwen2.5-7B-QLoRA
base_url = http://xxx.xxx.xxx/v1
api_key = inference_key
