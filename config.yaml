# Configuration for Machine B
data_dir: "data"
output_dir: "results"
metric_results_dir: "metric_results/agent/embedding"
recovery_rate_band: [0.85, 0.95]
lpm_call_rate_band: [0.25, 0.3]

inference:
  strong_model_path: "gpt-5"
  weak_model_path: "/path/to/Llama-3.1-8B-Instruct"
  max_tokens: 2048
  temperature: 0.0
  top_p: 0.9
  skip_special_tokens: true

  base_port: 8001  
  strong_gpu_ids: [3,4]
  weak_gpu_ids: [6,7]

  openai_api_key: "your_openai_api_key"
  openai_api_base: "your_openai_api_base"
  judge_model: "gpt-5"

  # Azure OpenAI configuration
  use_azure: false  # Set to true to use Azure OpenAI, false for OpenAI API

  max_workers: 1024
  batch_size: 8
  template_type: "default"
  system_prompt: "You are a helpful AI assistant."
  cuda_visible_devices: "0,1,2,3,6,7"

  # xVerify model configuration for math evaluation
  xverify_model_name: "xVerify"
  xverify_model_url: "http://127.0.0.1:8000/v1"
  xverify_inference_mode: "api"
  xverify_api_key: "dummy"

router:
  router_type: "embedding_mlp"

  model_path: "your_deberta_checkpoint_path"

  # Prefer directory lookup (hs-like): it will auto-pick "{task}_query_embeddings.pt" under this folder.
  embedding_dir: "your_embedding_dir"


  checkpoint_path: "embedding_mlp/test.pt"

  probe_type: "dynamic_dirichlet"
  num_samples: 20  # Used for semantic_entropy router

training:
  epochs: 50       
  batch_size: 32
  learning_rate: 0.0001   

  # Probe architecture parameters
  # mlp_hidden_dims: [64]  # Hidden layers for MLP probe, set to null or [] for single layer
  # mlp_dropout: 0.5  # Dropout rate for MLP probe layers

  logits_output_dir: "../hs"
  probe_save_path: "probe_save/base/probe"
  query_embedding_output_dir: "query_embeddings_output"
  embedding_mlp_save_path: "embedding_mlp"
  embedding_hidden_dims: [256, 64]
  embedding_dropout: 0.1
  seed: 42

  deberta_train_path: "your_deberta_train_path"
  deberta_val_path: null
  deberta_model_name: "your_deberta_model_name"
  deberta_num_labels: 2
  deberta_max_length: 512
  deberta_batch_size: 16
  deberta_learning_rate: 0.00001
  deberta_weight_decay: 0.01
  deberta_epochs: 3
  deberta_output_dir: "deberta_checkpoints/agent"
