# Configuration for Machine B
data_dir: "data"
output_dir: "results"
metric_results_dir: "metric_results/alpaca+big_math"
recovery_rate_band: [0.85, 0.95]
lpm_call_rate_band: [0.25, 0.3]

inference:
  # Machine B paths - modify these for your actual paths
  strong_model_path: "gpt-5"
  weak_model_path: "/volume/pt-train/users/wzhang/ghchen/zh/models/Qwen3-8B"
  # weak_model_path: "/volume/pt-train/models/Llama-3.1-8B-Instruct"
  max_tokens: 2048
  temperature: 0.0
  top_p: 0.9
  skip_special_tokens: true

  base_port: 8000  # Different port for Machine B
  strong_gpu_ids: [1, 0]
  weak_gpu_ids: [1,2,4,6]

  openai_api_key: "sk-e9OcUwV80NLvl00o73E5F3FcFa2d4a6cB7D46cB3D6263a1a"
  openai_api_base: "https://api.ai-gaochao.cn/v1"
  judge_model: "gpt-5"

  # Azure OpenAI configuration
  use_azure: false  # Set to true to use Azure OpenAI, false for OpenAI API

  max_workers: 1024
  batch_size: 8
  template_type: "default"
  system_prompt: "You are a helpful AI assistant."
  cuda_visible_devices: "1,2,4,6,7"

  # xVerify model configuration for math evaluation
  xverify_model_name: "xVerify"
  xverify_model_url: "http://127.0.0.1:8002/v1"
  xverify_inference_mode: "api"
  xverify_api_key: "dummy"

router:
  router_type: "probe"
  # checkpoint_path: "probe_save_dynamic/base/numina_cot_5k_train_dirichlet_probe.pt"
  checkpoint_path: "probe_save/base/probe/mixed_alpaca_5k_train_big_math_5k_train_dirichlet_probe.pt"
  probe_type: "dynamic_dirichlet" # "coe_dual_mlp"  "hs_mlp" “dynamic_dirichlet” "dynamic_softmax"
  model_path: null

training:
  epochs: 50
  batch_size: 32
  learning_rate: 0.0001

  # Probe architecture parameters
  # mlp_hidden_dims: [64]  # Hidden layers for MLP probe, set to null or [] for single layer
  # mlp_dropout: 0.5  # Dropout rate for MLP probe layers

  reward_model_name: "microsoft/deberta-v3-base"
  reward_output_dir: "reward_model"
  logits_output_dir: "../hs"
  probe_save_path: "probe_save/base/probe"
  seed: 42