# Configuration for Machine B
data_dir: "data"
output_dir: "results"
metric_results_dir: "metric_results/base"
recovery_rate_band: [0.85, 0.95]
lpm_call_rate_band: [0.25, 0.3]

inference:
  # Machine B paths - modify these for your actual paths
  strong_model_path: "gpt-5"
  weak_model_path: "/volume/pt-train/models/Llama-3.1-8B-Instruct"
  # weak_model_path: "/volume/pt-train/models/Qwen2.5-1.5B-Instruct"
#测qwen 2.5 7b的情况

  max_tokens: 2048
  temperature: 0.0
  top_p: 0.9
  skip_special_tokens: true

  base_port: 8001  # Different port for Machine B
  strong_gpu_ids: [1, 0]
  weak_gpu_ids: [0,1,2,3]

  openai_api_key: "sk-e9OcUwV80NLvl00o73E5F3FcFa2d4a6cB7D46cB3D6263a1a"
  openai_api_base: "https://api.ai-gaochao.cn/v1"
  judge_model: "gpt-5"

  max_workers: 1024
  batch_size: 8
  template_type: "default"
  system_prompt: "You are a helpful AI assistant."
  cuda_visible_devices: "0,1,2,3,4,5,6,7"

  # xVerify model configuration for math evaluation
  xverify_model_name: "xVerify-0.5B"
  xverify_model_url: "http://127.0.0.1:8000/v1"
  xverify_inference_mode: "api"
  xverify_api_key: "dummy"

router:
  router_type: "probe"
  # checkpoint_path: "probe_save_dynamic/base/numina_cot_5k_train_dirichlet_probe.pt"
  checkpoint_path: "/volume/pt-train/users/wzhang/ghchen/zh/CoBench/src/probe_save/one_dataset/mixed_alpaca_5k_train_math_mmlu_train_hs_last_mlp.pt"
  probe_type: "hs_last_mlp" # "coe_dual_mlp"  "hs_mlp" “dynamic_dirichlet” "dynamic_softmax"
  model_path: null

training:
  epochs: 50
  batch_size: 32
  learning_rate: 0.0001

  # Probe architecture parameters
  mlp_hidden_dims: [512]  # Hidden layers for MLP probe, set to null or [] for single layer

  reward_model_name: "microsoft/deberta-v3-base"
  reward_output_dir: "reward_model"
  logits_output_dir: "../hs"
  probe_save_path: "probe_save/qwen/"
  seed: 42